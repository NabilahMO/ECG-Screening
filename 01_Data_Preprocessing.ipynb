{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd6567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record: 100...\n",
      "Processing record: 101...\n",
      "Processing record: 102...\n",
      "Processing record: 103...\n",
      "Processing record: 104...\n",
      "Processing record: 105...\n",
      "Processing record: 106...\n",
      "Processing record: 107...\n",
      "Processing record: 108...\n",
      "Processing record: 109...\n",
      "Processing record: 111...\n",
      "Processing record: 112...\n",
      "Processing record: 113...\n",
      "Processing record: 114...\n",
      "Processing record: 115...\n",
      "Processing record: 116...\n",
      "Processing record: 117...\n",
      "Processing record: 118...\n",
      "Processing record: 119...\n",
      "Processing record: 121...\n",
      "Processing record: 122...\n",
      "Processing record: 123...\n",
      "Processing record: 124...\n",
      "Processing record: 200...\n",
      "Processing record: 201...\n",
      "Processing record: 202...\n",
      "Processing record: 203...\n",
      "Processing record: 205...\n",
      "Processing record: 207...\n",
      "Processing record: 208...\n",
      "Processing record: 209...\n",
      "Processing record: 210...\n",
      "Processing record: 212...\n",
      "Processing record: 213...\n",
      "Processing record: 214...\n",
      "Processing record: 215...\n",
      "Processing record: 217...\n",
      "Processing record: 219...\n",
      "Processing record: 220...\n",
      "Processing record: 221...\n",
      "Processing record: 222...\n",
      "Processing record: 223...\n",
      "Processing record: 228...\n",
      "Processing record: 230...\n",
      "Processing record: 231...\n",
      "Processing record: 232...\n",
      "Processing record: 233...\n",
      "Processing record: 234...\n",
      "\n",
      "\n",
      "Processing complete.\n",
      "Successfully saved all features to 'all_records_features.csv'\n",
      "Total heartbeats processed: 109448\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from Feature_Extraction import (\n",
    "    read_mit_bih_record,\n",
    "    filter_ecg_signal,\n",
    "    segment_heartbeats,\n",
    "    extract_features,\n",
    ")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # List of all 48 records in the database\n",
    "    mit_bih_records = [\n",
    "        '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', \n",
    "        '111', '112', '113', '114', '115', '116', '117', '118', '119', '121', \n",
    "        '122', '123', '124', '200', '201', '202', '203', '205', '207', '208', \n",
    "        '209', '210', '212', '213', '214', '215', '217', '219', '220', '221', \n",
    "        '222', '223', '228', '230', '231', '232', '233', '234'\n",
    "    ]\n",
    "    \n",
    "    database_directory = 'mit-bih-arrhythmia-database-1.0.0'\n",
    "    all_records_features = []\n",
    "\n",
    "    # Loop through each record in the list\n",
    "    for record_name in mit_bih_records:\n",
    "        record_data, annotation_data = read_mit_bih_record(record_name, database_directory)\n",
    "\n",
    "        if record_data and annotation_data:\n",
    "            raw_ecg_signal = record_data.p_signal[:, 0]\n",
    "            sampling_freq = record_data.fs\n",
    "\n",
    "            filtered_ecg_signal = filter_ecg_signal(raw_ecg_signal, sampling_freq)\n",
    "            segmented_beats, beat_labels, valid_r_peaks = segment_heartbeats(filtered_ecg_signal, annotation_data, sampling_freq)\n",
    "            \n",
    "            if not segmented_beats:\n",
    "                print(f\"No valid beats found for record {record_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            features = extract_features(segmented_beats, valid_r_peaks, sampling_freq)\n",
    "            \n",
    "            features_df = pd.DataFrame(features)\n",
    "            features_df['label'] = beat_labels\n",
    "            features_df['record'] = record_name\n",
    "            \n",
    "            all_records_features.append(features_df)\n",
    "\n",
    "    # Combine all the individual DataFrames into one\n",
    "    if all_records_features:\n",
    "        final_dataset = pd.concat(all_records_features, ignore_index=True)\n",
    "        \n",
    "        # Save the complete dataset to a single CSV file\n",
    "        output_filename = 'all_records_features.csv'\n",
    "        final_dataset.to_csv(output_filename, index=False)\n",
    "        \n",
    "        print(f\"\\n\\nProcessing complete.\")\n",
    "        print(f\"Successfully saved all features to '{output_filename}'\")\n",
    "        print(f\"Total heartbeats processed: {len(final_dataset)}\")\n",
    "    else:\n",
    "        print(\"\\n\\nProcessing complete. No data was generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
