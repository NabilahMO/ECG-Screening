{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd6567d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record: 100...\n",
      "Processing record: 101...\n",
      "Processing record: 102...\n",
      "Processing record: 103...\n",
      "Processing record: 104...\n",
      "Processing record: 105...\n",
      "Processing record: 106...\n",
      "Processing record: 107...\n",
      "Processing record: 108...\n",
      "Processing record: 109...\n",
      "Processing record: 111...\n",
      "Processing record: 112...\n",
      "Processing record: 113...\n",
      "Processing record: 114...\n",
      "Processing record: 115...\n",
      "Processing record: 116...\n",
      "Processing record: 117...\n",
      "Processing record: 118...\n",
      "Processing record: 119...\n",
      "Processing record: 121...\n",
      "Processing record: 122...\n",
      "Processing record: 123...\n",
      "Processing record: 124...\n",
      "Processing record: 200...\n",
      "Processing record: 201...\n",
      "Processing record: 202...\n",
      "Processing record: 203...\n",
      "Processing record: 205...\n",
      "Processing record: 207...\n",
      "Processing record: 208...\n",
      "Processing record: 209...\n",
      "Processing record: 210...\n",
      "Processing record: 212...\n",
      "Processing record: 213...\n",
      "Processing record: 214...\n",
      "Processing record: 215...\n",
      "Processing record: 217...\n",
      "Processing record: 219...\n",
      "Processing record: 220...\n",
      "Processing record: 221...\n",
      "Processing record: 222...\n",
      "Processing record: 223...\n",
      "Processing record: 228...\n",
      "Processing record: 230...\n",
      "Processing record: 231...\n",
      "Processing record: 232...\n",
      "Processing record: 233...\n",
      "Processing record: 234...\n",
      "\n",
      "\n",
      "Processing complete.\n",
      "Successfully saved all features to 'all_records_features.csv'\n",
      "Total heartbeats processed: 109448\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.stats import skew\n",
    "import os\n",
    "\n",
    "def read_mit_bih_record(record_name, data_dir='mit-bih-arrhythmia-database-1.0.0'):\n",
    "    #Reads a single record's signal and annotation data from the database.\n",
    "    try:\n",
    "        record_path = os.path.join(data_dir, record_name)\n",
    "        print(f\"Processing record: {record_name}...\")\n",
    "        record = wfdb.rdrecord(record_path)\n",
    "        annotation = wfdb.rdann(record_path, 'atr')\n",
    "        return record, annotation \n",
    "        \"\"\"\n",
    "        Returns a tuple containing: \n",
    "        wfdb.Record: The record object with signal data and metadata. \n",
    "        wfdb.Annotation: The annotation object with heartbeat labels.\n",
    "        \"\"\"\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Record files not found for '{record_name}'. Skipping.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for record '{record_name}': {e}. Skipping.\")\n",
    "        return None, None\n",
    "\n",
    "def filter_ecg_signal(signal, fs, lowcut=0.5, highcut=45.0, order=4):\n",
    "    \"\"\"\n",
    "    Applies a band-pass filter to the ECG signal and returns it as an np.array.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_signal = filtfilt(b, a, signal)\n",
    "    return filtered_signal\n",
    "\n",
    "def segment_heartbeats(signal, annotations, fs):\n",
    "    \"\"\"\n",
    "    This function segments the continuous ECG signal into individual heartbeats.\n",
    "    signal (np.array): The filtered ECG signal. \n",
    "    annotations (wfdb.Annotation): The annotation object.\n",
    "    fs (int): The sampling frequency.\n",
    "\n",
    "    It returns a tuple containing:\n",
    "    A list of numpy arrays, where each array is a heartbeat segment.\n",
    "    A list of the corresponding annotation symbols (labels) for each beat.\n",
    "    A list of the sample indices of the R-peaks for the segmented beats.\n",
    "    \"\"\"\n",
    "    before_samples = 100\n",
    "    after_samples = 180\n",
    "    \n",
    "    segmented_beats = []\n",
    "    beat_labels = []\n",
    "    valid_r_peak_locations = []\n",
    "\n",
    "    beat_annotation_symbols = ['N', 'L', 'R', 'B', 'A', 'a', 'J', 'S', 'V', 'r', 'F', 'e', 'j', 'n', 'E', '/', 'f', 'Q', '?']\n",
    "\n",
    "    r_peak_locations = annotations.sample\n",
    "    r_peak_symbols = annotations.symbol\n",
    "\n",
    "    for i in range(len(r_peak_locations)):\n",
    "        r_peak_loc = r_peak_locations[i]\n",
    "        symbol = r_peak_symbols[i]\n",
    "\n",
    "        if symbol in beat_annotation_symbols:\n",
    "            start = r_peak_loc - before_samples\n",
    "            end = r_peak_loc + after_samples\n",
    "\n",
    "            if start >= 0 and end < len(signal):\n",
    "                beat = signal[start:end]\n",
    "                segmented_beats.append(beat)\n",
    "                beat_labels.append(symbol)\n",
    "                valid_r_peak_locations.append(r_peak_loc)\n",
    "                \n",
    "    return segmented_beats, beat_labels, valid_r_peak_locations\n",
    "\n",
    "def extract_features(segmented_beats, valid_r_peaks, fs):\n",
    "    \"\"\"\n",
    "    Extracts features from each segmented heartbeat.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    \n",
    "    rr_intervals = np.diff(valid_r_peaks) / fs\n",
    "\n",
    "    for i, beat in enumerate(segmented_beats):\n",
    "        rr_prev = rr_intervals[i-1] if i > 0 else np.nan\n",
    "        rr_next = rr_intervals[i] if i < len(rr_intervals) else np.nan\n",
    "        \n",
    "        r_peak_amp = beat[100]\n",
    "        q_peak_amp = np.min(beat[:100])\n",
    "        s_peak_amp = np.min(beat[100:])\n",
    "        \n",
    "        mean_val = np.mean(beat)\n",
    "        std_val = np.std(beat)\n",
    "        skew_val = skew(beat)\n",
    "        \n",
    "        features = {\n",
    "            'rr_prev': rr_prev,\n",
    "            'rr_next': rr_next,\n",
    "            'r_peak_amp': r_peak_amp,\n",
    "            'q_peak_amp': q_peak_amp,\n",
    "            's_peak_amp': s_peak_amp,\n",
    "            'mean': mean_val,\n",
    "            'std': std_val,\n",
    "            'skew': skew_val\n",
    "        }\n",
    "        all_features.append(features)\n",
    "        \n",
    "    return all_features\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # List of all 48 records in the database\n",
    "    mit_bih_records = [\n",
    "        '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', \n",
    "        '111', '112', '113', '114', '115', '116', '117', '118', '119', '121', \n",
    "        '122', '123', '124', '200', '201', '202', '203', '205', '207', '208', \n",
    "        '209', '210', '212', '213', '214', '215', '217', '219', '220', '221', \n",
    "        '222', '223', '228', '230', '231', '232', '233', '234'\n",
    "    ]\n",
    "    \n",
    "    database_directory = 'mit-bih-arrhythmia-database-1.0.0'\n",
    "    all_records_features = []\n",
    "\n",
    "    # Loop through each record in the list\n",
    "    for record_name in mit_bih_records:\n",
    "        record_data, annotation_data = read_mit_bih_record(record_name, database_directory)\n",
    "\n",
    "        if record_data and annotation_data:\n",
    "            raw_ecg_signal = record_data.p_signal[:, 0]\n",
    "            sampling_freq = record_data.fs\n",
    "\n",
    "            filtered_ecg_signal = filter_ecg_signal(raw_ecg_signal, sampling_freq)\n",
    "            segmented_beats, beat_labels, valid_r_peaks = segment_heartbeats(filtered_ecg_signal, annotation_data, sampling_freq)\n",
    "            \n",
    "            if not segmented_beats:\n",
    "                print(f\"No valid beats found for record {record_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            features = extract_features(segmented_beats, valid_r_peaks, sampling_freq)\n",
    "            \n",
    "            features_df = pd.DataFrame(features)\n",
    "            features_df['label'] = beat_labels\n",
    "            features_df['record'] = record_name\n",
    "            \n",
    "            all_records_features.append(features_df)\n",
    "\n",
    "    # Combine all the individual DataFrames into one\n",
    "    if all_records_features:\n",
    "        final_dataset = pd.concat(all_records_features, ignore_index=True)\n",
    "        \n",
    "        # Save the complete dataset to a single CSV file\n",
    "        output_filename = 'all_records_features.csv'\n",
    "        final_dataset.to_csv(output_filename, index=False)\n",
    "        \n",
    "        print(f\"\\n\\nProcessing complete.\")\n",
    "        print(f\"Successfully saved all features to '{output_filename}'\")\n",
    "        print(f\"Total heartbeats processed: {len(final_dataset)}\")\n",
    "    else:\n",
    "        print(\"\\n\\nProcessing complete. No data was generated.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
